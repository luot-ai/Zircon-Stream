#  Stream Engine 工作机制说明

##  1. Stream Engine 基本结构


### 1.1 iCntMap（迭代计数器）

在流式计算中（如向量加 a[i] + b[i] → c[i]），每次执行一条 CALSTREAM（流计算指令）时，硬件必须知道：

> **这一条计算指令要使用 Buffer 中的第几个元素？**

例如：

* 第一次计算 → 使用 Buffer[0]
* 第二次计算 → 使用 Buffer[1]
* ……以此类推

为了实现这一点，每条流都对应一个迭代计数器，统一存放在 `iCntMap` 里

我们需要维护的逻辑是：

1. 不同流的计数器递增时机
2. 多发射的每条流计算指令如何根据计数器获取属于自己的index 


---

### 1.2 stream Buffer（每个 stream 一个）

每个 **stream 流** 分配：

* 一个 Buffer，包含 **X 项**
* 每项是 **4B word**
* 每项配套一个 1 bit flag


其中：

```scala
X = 2 × L2CacheLine_WORD
```

即：每个流有两个 cacheline 规模的双缓冲结构，分为两个半区

---

### 1.3 readyMap

大小和Buffer一样，每一项为1bit

| 流类型         | ready = 1             | ready = 0           |
| ----------- | --------------------- | ------------------- |
| **Load 流**  | 数据已经填充到 FIFO，可被计算单元读取 | 空闲，可从主存读取数据填充到 FIFO |
| **Store 流** | FIFO 中有计算结果，准备写回主存    | FIFO 空闲，计算单元可写入新结果  |



---

### 1.4 流地址与长度配置表

每个流在使用前需要配置好 **起始地址** 和 **burst总次数**，硬件通过两个寄存器向量维护这些信息，通过简单的指令即可完成配置：


* **addrCfg**：对应每个流的主存起始地址
* **lengthMap**：对应每个流的总burst次数

硬件上还需要维护**burst次数记录表**，每完成一次burst就递增，当到达配置值则不可再向主存发起请求



## 2. 流与存储系统交互（Load / Store 流）

### 2.1 Load 流：从主存读数据到 Buffer

**粒度：**
* 一次从AXI请求一个L2 Cacheline，对应双缓冲结构中的一个半区

**条件与限制：**

* 为了实现简便，取数一个条件是 Buffer某个半区的所有项 ready = 0（空闲）
* 取数的另一个条件是该流的burst次数未超过其配置次数
* 各流按半区0->半区1->半区0->半区1这样的方式取数，并且半区0取第0、2、4、6...组cacheline数据，半区0取第1、3、5、7...组cacheline数据

**过程：**

1. **select stream**
   从 Buffer 空闲、配置完毕的流中选择一个读主存。
2. **AXI 读请求**
   直连 AXI Arbiter，与 L2 竞争带宽。
3. **写入 Buffer：**
   依次写入要填入的半区：
4. 写完数据 有如下副作用
   1. `ready = 1`
   2. burstCnt递增
   3. addrCfg递增（当前仅实现线性流）

---

### 2.2 Store 流：Buffer → 主存

**条件：**

* store Buffer 某个半区 所有index  `ready = 1`

**过程：**

1. **判断是否可写**
2. **AXI 写入主存**
3. 写回主存有如下副作用 
   1. `ready = 0`
   2. burstCnt递增
   3. addrCfg递增（当前仅实现线性流）


# 3. CALSTREAM 指令在流水线中的流动（Dispatch -> Issue -> Execute -> Writeback）

CALSTREAM（流计算指令）会从Buffer中读数，计算，写回，完成一次元素级计算

为了保证正确的数据依赖与吞吐，硬件对 CALSTREAM 做了完整的流水处理：


# **3.1 Dispatch 阶段：为流计算指令分配 index**




### **① 获取当前这条指令对应的 index**

因为 流计算指令在issue级需要index判断是否可以发射，因此需要在issue级之前获取index，这里选择在dispatch级获取

关键是要让dispatch宽度内的calstream指令获取正确的index值。例如，假设当前itermap中该流对应的计数器值是25，而dispatch宽度是3，并且第1条和第3条指令都是流计算指令，那么他们的index值分别应该是25(%32)和26(%32):

```
index = iterCnt % Buffer_Depth
```

### **② 增迭代计数器（iCntMap）**

CALSTREAM 在 dispatch 获取index，会对itermap产生副作用，dispatch级有多少条流计算指令下一周期可通过该级(fire)，itermap中对应流的计数器就要增加多少

> 可能需要维护分支预测失误下itermap的恢复


# **3.2 Issue 阶段：检查 Buffer 是否就绪（指令能不能发射？）**

Issue 阶段决定该 CALSTREAM 指令是否可以真正进入执行单元。

对于每个计算指令（例如 a[i] + b[i] → c[i]），Issue 必须检查：

* **Load 流的 Buffer 对应 index 的 ready == 1（有数据可读）**
* **Store 流的 Buffer 对应 index 的 ready == 0（有空位可写）**

示例（向量加）：

| 流 | 类型    | 条件                  |
| - | ----- | ------------------- |
| A | Load  | readyMap(0)[i] == 1 |
| B | Load  | readyMap(1)[i] == 1 |
| C | Store | readyMap(2)[i] == 0 |


只有三个条件都满足，这条指令才允许发射。


# **3.3 Execute 阶段：读取 → 计算 → 写回**

Execute 包含三个流水级，与普通整数指令风格保持一致：


## **3.3.1 ReadOp（操作数读取）**

流计算指令有特殊的opcode，带有这种opcode的指令会从Buffer 中取出本次计算需要的操作数：

```
rdata1 = Buffer(A)[index]
rdata2 = Buffer(B)[index]
```



## **3.3.2 ALU 计算**

当前版本的 ops 写死为加法：

```
result = rdata1 + rdata2
```

未来可以扩展为更多流式计算（乘、MAC、激活函数等），这个是很容易实现的


## **3.3.3 Writeback（写入 store Buffer）**

向 store Buffer 中写入，同时更改对应index的flag：

```
Buffer(C)[index] = result
readyMap(C)[index] = 1          // 标记此项可被写回主存
readyMap(A)[index] = 0          // load 流项已被消费
readyMap(B)[index] = 0
```

这一步完成后：

* load 流对应 index 清空，可被下一轮访存填充
* store 流对应 index 变为 ready，可被 AXI 写回主存


#  4. 向量加（Vector Add）执行示例

下面以三个流（a、b、c）说明 512 elements vector add：

```
c[i] = a[i] + b[i]
```


## 4.1 Buffer 分配

每个流分配：

* 一个pingpong buffer（两个半区）：`line0` 和 `line1`
* 每个半区含 一个l2 cacheline（32 个 word）
* 每 word 搭配 1bit ready 标志


双缓冲结构保证计算与访存可完全重叠。


## 4.2 执行步骤

### (a) 指令配置

配置：

* a, b 的起始地址
* 每次取 32 word
* 共需 512 word → 16 次 burst

---

### (b) 第一批取数：填 line0

AXI 依次取：

```
a[0..31] → a.line0
b[0..31] → b.line0
```

ready 置 1。

---

### (c) 第一轮计算（0–31）+ 第二批取数（32–63）

计算单元开始：

```
c[i] = a[i] + b[i],  i = 0..31
```
算好后load流相应line0中的ready位会拉低，store流的会拉高

同时 AXI 获取下一批：

```
a[32..63] → line1
b[32..63] → line1
```

---

### (d) 第二轮计算（32–63）+ 第三批取数（64–95）

第二轮计算开始：

```
c[i] = a[i] + b[i], i = 32..63
```

准备从主存获取下一批（64–95）到 line0。


由于line1已经取好，并且计算速度(line0的消费速度)快于访存(line1的取数速度)，因此两个load流的line0肯定已经被拉低，所以可以取数


```
a[32..63] → line0
b[32..63] → line0
```

---

### (e) 第 n 轮循环

双缓冲循环往复：

```
计算本批（i）
访存下一批（i+1）
```

直到 16 轮完成所有 512 word 计算。



## 4.3 执行效果

* AXI 访存几乎无空闲
* 计算完全被访存隐藏
* 每轮延迟 ≈ 两次 32-word 读的耗时
* 增大 burst size 可进一步减少握手带宽损耗

最终实际测量：

```
≈ 1700–1800 cycle 完成整段 vector add
```



