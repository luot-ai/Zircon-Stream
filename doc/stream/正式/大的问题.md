## 1. 转置的开销

### 结合Stream Engine 软硬件协同 做转置

- [性能分析](../work/V2/analysis.md)
- 硬件开销 

1. 新增`strideCfg`字步长寄存器 和 `tileStrideCfg`Tile步长寄存器，每个流多分配了2个32bit寄存器
2. 取数地址寄存器更新逻辑变化：原来取相邻 word 只需要+4byte，现在需要+strideCfg
3. tile首地址寄存器更新逻辑变化：原来取完某tile 会直接+4*32byte，现在需要+tileStrideCfg

但这些更新都不是**专门为了转置而实现的**，字步长寄存器和Tile步长寄存器可以实现比较丰富的地址生成Pattern，转置只是其中的一个Pattern。流Engine实现转置的方式就是 做好地址的更新，向Cache发送列数据请求，Cache具体做了什么对于Stream Engine是个黑盒

- 软件开销
2条配置指令完成`strideCfg`和`tileStrideCfg`的配置即可



### 纯软件做转置

- [性能分析](../work/V2/analysis.md)
- 无硬件开销
- 软件开销就是多写了点转置代码


## 2. Stream应该连接的存储层级

目前Stream可配置为仅向AXI发送请求 或 仅向L2发送请求

- Stream应该与L2直连，而不是与L1直连：
1. 增加与Cache的接口是需要Cache起到一个缓存的作用，但其实似乎缓存在L2中就行了，没必要把数据再取到L1中倒腾一下
2. 目前还没想到什么**必须要与L1直连**的理由，当时实现与L1直连可能是出于代码设计复杂度的考虑


## 3. Stream Buffer 是Reg还是Sram？

参考CPU里的62个物理寄存器，5*2=10读口 5个写口
目前流Engine是64个寄存器，4*2=8个读口 4(+2)个写口

**当然，如果流水线扩展成向量肯定就不够了**

## 4. Stream Buffer 与SPM相连？