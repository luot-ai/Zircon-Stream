## 1. 转置的开销

### 结合Stream Engine 软硬件协同 做转置

- TODO性能测试
- 硬件开销 

1. 新增`strideCfg`字步长寄存器 和 `tileStrideCfg`Tile步长寄存器，每个流多分配了2个32bit寄存器
2. 取数地址寄存器更新逻辑变化：原来取相邻 word 只需要+4byte，现在需要+strideCfg
3. tile首地址寄存器更新逻辑变化：原来取完某tile 会直接+4*32byte，现在需要+tileStrideCfg

但这些更新都不是**专门为了转置而实现的**，字步长寄存器和Tile步长寄存器可以实现比较丰富的地址生成Pattern，转置只是其中的一个Pattern。流Engine实现转置的方式就是 做好地址的更新，向Cache发送列数据请求，Cache具体做了什么对于Stream Engine是个黑盒

- 软件开销
2条配置指令完成`strideCfg`和`tileStrideCfg`的配置即可



### 纯软件做转置

- TODO性能测试：看绝对时间
- 无硬件开销
- 软件开销就是多写了点转置代码


## 2. Stream应该位于的存储层级

原来Stream仅向DDR发送请求，目前Stream仅向L1发送请求

- Stream应该增加与DDR的接口，允许某些不需要Cache作为后备缓存的流直接访问DDR

- Stream应该与L2直连，而不是与L1直连：
1. 增加与Cache的接口是需要Cache起到一个缓存的作用，但其实似乎缓存在L2中就行了，没必要把数据再取到L1中倒腾一下
2. 目前还没想到什么**必须要与L1直连**的理由，当时实现与L1直连可能是出于代码设计复杂度的考虑
